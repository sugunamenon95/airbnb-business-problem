---
title: "airbnb_north_america"
author: "Teguh Samudra"
date: "9/15/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Libraries

```{r loadLibraries}
#Load PostgreSQL, knitr, dplyr
library(RPostgreSQL)
library(knitr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(readr)
library(tidyr)

```


```{r getAirbnbListing}

if (!dir.exists("data/input/")) {
  if (!dir.exists("data")) {
    dir.create("data")
  }
  dir.create("data/input")
}

if (!file.exists("data/input/airbnb-listings.csv")) {
  download.file("https://public.opendatasoft.com/explore/dataset/airbnb-listings/download/?format=csv&timezone=America/Los_Angeles&use_labels_for_header=true",
  "data/input/airbnb-listings.csv")
}

```
{r Count total rows and columns in dataset}
file_csv_raw <- "data/input/airbnb-ratings.csv"
filepath_csv <- read.csv(file_csv_raw, header = TRUE, sep = ';')

row_total_dirty <- nrow(filepath_csv)
col_total_dirty <- ncol(filepath_csv)
colnames(filepath_csv) <- tolower(colnames(filepath_csv))



```{r cleanData}

if (!file.exists('data/output/airbnb-listings.rds')) {
  file_raw <- read.csv("data/input/airbnb-listings.csv",header = TRUE, sep = ';')
  file_reduced <- file_raw %>%
    #filter(Country.Code == 'US')
    select(host_id = 'Host.ID',
           host_since = "Host.Since",
           host_location = "Host.Location",
           host_response_time = "Host.Response.Time",
           host_listings_count = "Host.Listings.Count",
           host_total_listings_count = "Host.Total.Listings.Count",
           property_type = "Property.Type",
           room_type = "Room.Type",
           minimum_nights = "Minimum.Nights",
           number_of_reviews = "Number.of.Reviews",
           review_score_rating =  "Review.Scores.Rating",
           review_score_accuracy = "Review.Scores.Accuracy",
           review_score_cleanliness = "Review.Scores.Cleanliness",
           review_score_checkin = "Review.Scores.Checkin",
           review_score_location = "Review.Scores.Location",
           cancellation_policy = "Cancellation.Policy",
           city = "City",
           state = "State",
           zipcode = "Zipcode",
           latitude = "Latitude",
           longitude = "Longitude",
           accommodates = "Accommodates",
           price = "Price",
           country_code = "Country.Code"
           ) %>%
                filter(country_code == 'US') %>%
                  filter(!(property_type == 'Casa particular' |
                         property_type == 'Train' |
                         property_type == 'Plane' |
                         property_type == 'Parking Space' |
                         property_type == 'Van' |
                        property_type == '2017-04-02' |
                       property_type == 'Car'|
                         property_type == 'Boat'))
                
  if (!file.exists('data/output')) {
    dir.create('data/output')
  }
  saveRDS(file_reduced, 'data/output/airbnb-listings.rds')
} else {
  file_reduced <- readRDS('data/output/airbnb-listings.rds')
}

```



## Import File and show column names
```{r}
file_clean_na <- "data/clean_na.csv"
file_cna <- read.csv(file_clean_na, header = TRUE)

total_row1 <- nrow(file_cna)
total_col1 <- ncol(file_cna)
colnames(file_cna)
```

There are about `r total_row1` rows and `r total_col1` columns. 
## Columns and its data type
```{r}
glimpse(file_cna)
```

## City
```{r}
city_summary <- file_cna %>%
                  group_by(city) %>%
                  count()
nrow(city_summary)
```

There are about `r nrow(city_summary)` unique registered cities from the listings. 

```{r}
uniq_city <- unique(file_cna$city)
head(uniq_city, 10)
```
```{r}
tail(uniq_city,10)
```

## State
```{r}
state_summary <- file_cna %>%
                  group_by(state) %>%
                  count()
nrow(state_summary)
```


```{r}
head(state_summary)
```


```{r}
tail(state_summary)
```
## Cancelation Policy
```{r}
cancel_summary <- file_cna %>%
                  group_by(cancellation.policy) %>%
                  summarise(cancel_pol = n()) %>%
                  arrange(desc = cancel_pol) %>%
                  head()

```

```{r}
#barplot(cancel_summary$cancel_pol,
        #xlab = 'Cancelation Policy',
        #ylab = 'Total')

#axis(side = 1, at = seq_along(cancel_summary$cancel_pol)  - 0.5, tick = FALSE, labels = cancel_summary$cancellation.policy)
ggplot(cancel_summary, aes(x = cancel_summary$cancellation.policy, y = cancel_summary$cancel_pol)) + geom_col()

```

## Unique Property
```{r}
uniq_type <- file_cna %>%
                  group_by(property.type) %>%
                  summarise(proper_type = n()) %>%
                  arrange(desc(proper_type)) %>%
                  head(10)

ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) + 
  geom_col() + theme(axis.text.x = element_text(angle = 90)) +geom_text(aes(label=proper_type), position=position_dodge(width=0.9), vjust=-0.25)
```


## Price
```{r}
# Count the number of rows in price column that has NA
sum(is.na(file_cna$price))

```

```{r}
#Create a new data frame that exclude Price == NA
file_cna2 <- file_cna[!is.na(file_cna$price),]
row_substracted <- nrow(file_cna) - nrow(file_cna2)
row_substracted
```
```{r convertToDate}
file_cna2$host.since <- as.Date(file_cna2$host.since, format = '%Y-%m-%d')
file_cna2$first.review <- as.Date(file_cna2$first.review, format = '%Y-%m-%d')
file_cna2$last.review <- as.Date(file_cna2$last.review, format = '%Y-%m-%d')
file_cna2$calendar.last.scraped <- as.Date(file_cna2$calendar.last.scraped, format = '%Y-%m-%d')
```



```{r}
#remove 5-experience offered
#remove 14-host verification
#remove 16-neighborhoos.cleansed
#remove 17-Neighborhood.group cleansed
#remove 22-smart location
#remove 24-country.country code already exist. 
#remove 34
#remove 40-cleaning fee
#remove 66-geolocation(data already contain longitude and latitude)
col_remove <- c(5, 14, 16, 17, 22, 24, 34, 40, 66)
file_cna3 <- file_cna2[-col_remove]
```

```{r}
#file price in different zipcode
zip_price_avg_ca <- file_cna3 %>%
                    filter(country.code == 'CA') %>%
                    group_by(zipcode)%>%
                    summarise(avg_price = mean(price)) %>%
                    arrange(desc(avg_price))

zip_price_avg_us <- file_cna3 %>%
                    filter(country.code == 'US') %>%
                    group_by(zipcode)%>%
                    summarise(avg_price = mean(price)) %>%
                    arrange(desc(avg_price))

```


{r checkUniqueKey}
unique_key <- file_cna3 %>%
                distinct(host.id) %>%
                nrow
print(unique_key)

unique_key2 <- file_cna3 %>%
                distinct(host.id) %>%
                nrow
print(unique_key2)


```{r}
price_v_ratings_us <- file_cna3 %>%
                  filter(country.code == 'US' ) %>%
                  group_by(price, review.scores.rating)

ggplot(price_v_ratings_us, aes(x = price_v_ratings_us$price, y = price_v_ratings_us$review.scores.rating )) + geom_point()
              
```


## Establishing connection with the database

We create a PostgreSQL database for our data.  Both datasets include geographic data, at the provincial level.

```{r dbConnect}

# Build will fail if the file isn't there.
assertthat::assert_that(file.exists('db_connect.txt'),
  msg = "Your connection file is missing.")

con_file <- readr::read_lines('db_connect.txt')

con <- RPostgreSQL::dbConnect(
             PostgreSQL(),
             host = con_file[1],
             port = con_file[2],
             user = con_file[3],
         password = con_file[4],
           dbname = con_file[5])

```

```{r renaming column names}

names(file_cna3)[5] <- "host_id"
names(file_cna3)[6] <- "host_since"
names(file_cna3)[7] <- "host_location"
names(file_cna3)[8] <- "host_response_time"
names(file_cna3)[11] <- "host_listings_count"
names(file_cna3)[12] <- "host_total_listings_count"
names(file_cna3)[21] <- "property_type"
names(file_cna3)[22] <- "room_type"
names(file_cna3)[35] <- "minimum_nights"
names(file_cna3)[44] <- "number_of_reviews"
names(file_cna3)[47] <- "review_score_rating"
names(file_cna3)[48] <- "review_score_accuracy"
names(file_cna3)[49] <- "review_score_cleanliness"
names(file_cna3)[50] <- "review_score_checkin"
names(file_cna3)[52] <- "review_score_location"
names(file_cna3)[55] <- "cancellation_policy"
```


## Creating datasets to be written to the database

```{r create dataframes for tables to be created in the database}

host_data <- file_cna3[c('host_id', 'host_since', 'host_location', 'host_response_time', 'host_total_listings_count', 'host_listings_count')]


location <- file_cna3[c('zipcode', 'latitude', 'longitude', 'city', 'state')]

property <- file_cna3[c('zipcode', 'host_id', 'minimum_nights', 'property_type', 'room_type', 'accomodates', 'price', 'number_of_reviews', 'cancellation_policy')]

reviews <- file_cna3[c('review_score_rating', 'review_score_cleanliness', 'review_score_accuracy', 'review_score_checkin', 'review_score_location')]

```


## Creating function that will be called to write all the tables in the database

```{r postDataFunction to insert tables in the database}
post_data <- function(con, x, tablename = "") {
  if (dbExistsTable(con, tablename)) {
    dbExecute(con,
      paste0("DROP TABLE ", tablename,
             " CASCADE"))
  }

  dbWriteTable(con,
               tablename,
               x,
               row.names = FALSE,
               overwrite = TRUE)
}
```


## Write tables to the database 

```{r Write tables to database}

post_data(con,
            data.frame(review_id = 1:nrow(reviews),reviews),
            "reviews")

dbExecute(con,
  "ALTER TABLE reviews ADD PRIMARY KEY (review_id)")

post_data(con,
            host_data,
            "host")

post_data(con,
            location,
            "location")

post_data(con,
            data.frame(property_id = 1:nrow(property),property),
            "property")

dbExecute(con,
  "ALTER TABLE property ADD PRIMARY KEY (property_id)")


```

## List all tables present in the database

```{r listTables, eval=FALSE}
dbListTables(con)
```
