group_by(city) %>%
count()
nrow(city_summary)
uniq_city <- unique(file_cna$city)
head(uniq_city, 10)
tail(uniq_city,10)
state_summary <- file_cna %>%
group_by(state) %>%
count()
nrow(state_summary)
head(state_summary)
tail(state_summary)
cancel_summary <- file_cna %>%
group_by(cancellation.policy) %>%
summarise(cancel_pol = n()) %>%
arrange(desc = cancel_pol) %>%
head()
#barplot(cancel_summary$cancel_pol,
#xlab = 'Cancelation Policy',
#ylab = 'Total')
#axis(side = 1, at = seq_along(cancel_summary$cancel_pol)  - 0.5, tick = FALSE, labels = cancel_summary$cancellation.policy)
ggplot(cancel_summary, aes(x = cancel_summary$cancellation.policy, y = cancel_summary$cancel_pol)) + geom_col()
uniq_type <- file_cna %>%
group_by(property.type) %>%
summarise(proper_type = n()) %>%
arrange() %>%
head()
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col()
# Count the number of rows in price column that has NA
sum(is.na(file_cna$price))
#Create a new data frame that exclude Price == NA
file_cna2 <- file_cna[!is.na(file_cna$price),]
row_substracted <- nrow(file_cna) - nrow(file_cna2)
row_substracted
unique(file_cna2$host.since)
file_cna2$host.since <- as.Date(file_cna2$host.since, format = '%Y-%m-%d')
class(file_cna2$host.since)
sum(is.na(file_cna2$price))
is.na(file_cna2$price)
?count
price_nona <- file_cna2 %>%
filter(is.na(price)) %>%
nrow
price_nona
unique(file_cna2$price)
glimpse(file_cna2)
colnames(file_cna2)
col_remove <- c(66)
file_cna3 <- file_cna2[-col_remove, ]
colnames(file_cna3)
file_cna3 <- file_cna2[-col_remove]
colnames(file_cna3)
glimpse(file_cna3)
head(file_cna3$scrape.id)
file_cna2$first.review <- as.Date(file_cna2$first.review, format = '%Y-%m-%d')
col_remove <- c(66)
file_cna3 <- file_cna2[-col_remove]
class(file_cna3$first.review)
file_cna2$last.review <- as.Date(file_cna2$last.review, format = '%Y-%m-%d')
col_remove <- c(66)
file_cna3 <- file_cna2[-col_remove]
class(file_cna3$last.review)
glimpse(file_cna3)
file_cna2$host.since <- as.Date(file_cna2$host.since, format = '%Y-%m-%d')
file_cna2$first.review <- as.Date(file_cna2$first.review, format = '%Y-%m-%d')
file_cna2$last.review <- as.Date(file_cna2$last.review, format = '%Y-%m-%d')
file_cna2$calendar.last.scraped <- as.Date(file_cna2$calendar.last.scraped, format = '%Y-%m-%d')
colnames(file_cna2)
col_remove <- c(14,66)
file_cna3 <- file_cna2[-col_remove]
colnames(file_cna3)
glimpse(file_cna3)
colnames(file_cna2)
col_remove <- c(14, 22, 66)
file_cna3 <- file_cna2[-col_remove]
unique(file_cna3$experiences.offered)
unique(file_cna3$host.acceptance.rate)
unique(file_cna3$country.code)
colnames(file_cna2)
unique(file_cna3$jurisdiction.names)
col_remove <- c(5, 14, 22, 24, 66)
file_cna3 <- file_cna2[-col_remove]
glimpse(file_cna3)
unique(file_cna3$neighbourhood.cleansed)
unique(file_cna3$neighbourhood.group.cleansed)
colnames(file_cna2)
col_remove <- c(5, 14, 17, 22, 24, 66)
file_cna3 <- file_cna2[-col_remove]
glimpse(file_cna3)
unique(file_cna3$market)
colnames(file_cna2)
col_remove <- c(5, 14, 17, 22, 24, 40, 66)
file_cna3 <- file_cna2[-col_remove]
glimpse(file_cna3)
unique(file_cna3$neighbourhood.cleansed)
tail(unique(file_cna3$neighbourhood.cleansed))
colnames(file_cna2)
col_remove <- c(5, 14, 16, 17, 22, 24, 40, 66)
file_cna3 <- file_cna2[-col_remove]
glimpse(file_cna3)
#file price in different zipcode
zip_price_avg <- file_cna3 %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price))
zip_price_avg
#file price in different zipcode
zip_price_avg <- file_cna3 %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange()
zip_price_avg
tail(zip_price_avg)
?arrange
#file price in different zipcode
zip_price_avg <- file_cna3 %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange(avg_price)
zip_price_avg
#file price in different zipcode
zip_price_avg <- file_cna3 %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange(desc(avg_price))
zip_price_avg
zip_price_avg_ca <- file_cna3 %>%
filter(country.code == 'CA')
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange(desc(avg_price))
unique(file_cna3$country.code)
#file price in different zipcode
zip_price_avg_ca <- file_cna3 %>%
filter(country.code == 'CA') %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange(desc(avg_price))
zip_price_avg_ca
zip_price_avg_us <- file_cna3 %>%
filter(country.code == 'US') %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange(desc(avg_price))
zip_price_avg_us
glimpse
glimpse(file_cna3)
knitr::opts_chunk$set(echo = TRUE)
#Load PostgreSQL, knitr, dplyr
library(RPostgreSQL)
library(knitr)
library(dplyr)
library(ggplot2)
file_clean_na <- "data/clean_na.csv"
file_cna <- read.csv(file_clean_na, header = TRUE)
total_row1 <- nrow(file_cna)
total_col1 <- ncol(file_cna)
colnames(file_cna)
glimpse(file_cna)
city_summary <- file_cna %>%
group_by(city) %>%
count()
nrow(city_summary)
uniq_city <- unique(file_cna$city)
head(uniq_city, 10)
tail(uniq_city,10)
state_summary <- file_cna %>%
group_by(state) %>%
count()
nrow(state_summary)
head(state_summary)
tail(state_summary)
cancel_summary <- file_cna %>%
group_by(cancellation.policy) %>%
summarise(cancel_pol = n()) %>%
arrange(desc = cancel_pol) %>%
head()
#barplot(cancel_summary$cancel_pol,
#xlab = 'Cancelation Policy',
#ylab = 'Total')
#axis(side = 1, at = seq_along(cancel_summary$cancel_pol)  - 0.5, tick = FALSE, labels = cancel_summary$cancellation.policy)
ggplot(cancel_summary, aes(x = cancel_summary$cancellation.policy, y = cancel_summary$cancel_pol)) + geom_col()
uniq_type <- file_cna %>%
group_by(property.type) %>%
summarise(proper_type = n()) %>%
arrange() %>%
head()
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col()
# Count the number of rows in price column that has NA
sum(is.na(file_cna$price))
#Create a new data frame that exclude Price == NA
file_cna2 <- file_cna[!is.na(file_cna$price),]
row_substracted <- nrow(file_cna) - nrow(file_cna2)
row_substracted
file_cna2$host.since <- as.Date(file_cna2$host.since, format = '%Y-%m-%d')
file_cna2$first.review <- as.Date(file_cna2$first.review, format = '%Y-%m-%d')
file_cna2$last.review <- as.Date(file_cna2$last.review, format = '%Y-%m-%d')
file_cna2$calendar.last.scraped <- as.Date(file_cna2$calendar.last.scraped, format = '%Y-%m-%d')
#remove 5-experience offered
#remove 14-host verification
#remove 16-neighborhoos.cleansed
#remove 17-Neighborhood.group cleansed
#remove 22-smart location
#remove 24-country.country code already exist.
#remove 40-cleaning fee
#remove 66-geolocation(data already contain longitude and latitude)
col_remove <- c(5, 14, 16, 17, 22, 24, 40, 66)
file_cna3 <- file_cna2[-col_remove]
#file price in different zipcode
zip_price_avg_ca <- file_cna3 %>%
filter(country.code == 'CA') %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange(desc(avg_price))
zip_price_avg_us <- file_cna3 %>%
filter(country.code == 'US') %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange(desc(avg_price))
zip_price_avg_us
zip_price_avg_ca
ggplot(cancel_summary, aes(x = cancel_summary$cancellation.policy, y = cancel_summary$cancel_pol)) + geom_col()
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col()
uniq_type
uniq_type <- file_cna %>%
group_by(property.type) %>%
summarise(proper_type = n()) %>%
arrange() %>%
head(10)
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col()
uniq_type <- file_cna %>%
group_by(property.type) %>%
summarise(proper_type = n()) %>%
arrange() %>%
head(7)
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col()
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col() + theme(axis.text.x = element_text(angle = 90))
uniq_type <- file_cna %>%
group_by(property.type) %>%
summarise(proper_type = n()) %>%
arrange() %>%
head(10)
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col() + theme(axis.text.x = element_text(angle = 90))
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col() + theme(axis.text.x = element_text(angle = 90)) +geom_text(aes(label=Number), position=position_dodge(width=0.9), vjust=-0.25)
uniq_type
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col() + theme(axis.text.x = element_text(angle = 90)) +geom_text(aes(label=proper_type), position=position_dodge(width=0.9), vjust=-0.25)
uniq_type <- file_cna %>%
group_by(property.type) %>%
summarise(proper_type = n()) %>%
arrange(proper_type) %>%
head(10)
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col() + theme(axis.text.x = element_text(angle = 90)) +geom_text(aes(label=proper_type), position=position_dodge(width=0.9), vjust=-0.25)
uniq_type
uniq_type <- file_cna %>%
group_by(property.type) %>%
summarise(proper_type = n()) %>%
arrange(desc(proper_type)) %>%
head(10)
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col() + theme(axis.text.x = element_text(angle = 90)) +geom_text(aes(label=proper_type), position=position_dodge(width=0.9), vjust=-0.25)
ggplot(uniq_type, aes(x = uniq_type$property.type, y = uniq_type$proper_type)) +
geom_col() + theme(axis.text.x = element_text(angle = 90)) +geom_text(aes(label=proper_type), position=position_dodge(width=0.9), vjust=-0.25)
colnames(file_cna3)
#file price in different zipcode
zip_price_avg_ca <- file_cna3 %>%
filter(country.code == 'CA') %>%
group_by(city)%>%
summarise(avg_price = mean(price)) %>%
arrange(desc(avg_price))
zip_price_avg_ca
#file price in different zipcode
zip_price_avg_ca <- file_cna3 %>%
filter(country.code == 'CA') %>%
group_by(zipcode)%>%
summarise(avg_price = mean(price)) %>%
arrange(desc(avg_price))
zip_price_avg_ca
file_cna3$last.scraped
library(RPostgreSQL)
library(dplyr)
library(purrr)
library(purrrlyr)
#map reduce
library(sf)
#working with spatial data
library(randomNames)
#work with fake data
library(assertthat)
library(sentimentr)
# Build will fail if the file isn't there.
assertthat::assert_that(file.exists('db_connect.txt'),
msg = "Your connection file is missing.")
con_file <- readr::read_lines('db_connect.txt')
con <- RPostgreSQL::dbConnect(
PostgreSQL(),
host = con_file[1],
port = con_file[2],
user = con_file[3],
password = con_file[4],
dbname = con_file[5])
nameTables <- data.frame(people = c("drivers",
"passengers",
"dispatchers"),
number = c(2000, 200000, 200),
stringsAsFactors = FALSE)
personName <- nameTables  %>%
by_row(function(x) {
randomNames::randomNames(x$number)
}, .labels = FALSE) %>%
unlist(recursive = FALSE)
split_name <- function(x) {
splitName <- strsplit(x, ",")[[1]]
data.frame(first = splitName[2],
last  = splitName[1],
stringsAsFactors = FALSE)
}
# Split apart the names, then add a unique ID.
allNames <- personName %>%
map(function(x) lapply(x, split_name) %>%
bind_rows()) %>% #because split row create different dataframe, you need to bind them back
map(function(x) {
x$pid <- 1:nrow(x)
return(x)
})
names(allNames) <- nameTables$people
drivers <- allNames$drivers %>%
mutate(province = "BC",
license = length(pid) %>%
runif(1e7, 1e8) %>% #random uniform number
floor, #round to base value
renewed = as.Date("2011-01-01") +
rgamma(1:2000, 4, 8) *
(5 * 365))
drivers$renewed[drivers$renewed >= as.Date(Sys.Date())] <- as.Date(Sys.Date() - 1)
assertthat::assert_that(all(drivers$renewed < as.Date(Sys.Date())))
if (!dir.exists("data/vanhoods/")) {
if (!dir.exists("data")) {
dir.create("data") #create a folder in directory
}
dir.create("data/vanhoods")
}
if (!file.exists("data/vanhoods/")) {
download.file("ftp://webftp.vancouver.ca/OpenData/shape/local_area_boundary_shp.zip",
"data/vanhoods/local_area_boundary_shp.zip")
unzip("data/vanhoods/local_area_boundary_shp.zip",
exdir = "data/vanhoods")
}
places <- sf::st_read("data/vanhoods/local_area_boundary.shp")
# EPSG: 26910
# +proj=utm +zone=10 +datum=NAD83 +units=m +no_defs
n_hoods <- nrow(places[1])
locs <- data.frame(coords = st_as_text(sf::st_sample(places,
rep(20000,n_hoods))),
zone = rep(as.character(places$NAME),
each = 20000),
stringsAsFactors = FALSE)
locs$plid <- 1:nrow(locs)
no_cars <- 2100
car_make <- data.frame(modelid = 1:4,
make = c("Ford", "Fiat",
"SAIC", "Tata"),
model = c("Fiesta", "500",
"Roewe", "Tigor"),
stringsAsFactors = FALSE)
lsa <- function(x) { sample(letters, x,
replace = TRUE) }
nsa <- function(x) { sample(0:9, x, replace = TRUE) }
cars <- data.frame(carid = 1:no_cars,
modelid = sample(car_make$modelid,
2100,
replace = TRUE),
license = paste0(lsa(2100),
nsa(2100),
lsa(2100),
nsa(2100),
lsa(2100),
nsa(2100)))
date_seq <- seq(from = as.Date("2014-01-01"),
to = as.Date("2019-01-01"),
by = 1)
date_prob <- (date_seq %>%
lubridate::wday()) %in% c(1,7) %>%
if_else(., 0.3, 0.7)
ride_date <- sort(sample(date_seq,
size = 20000,
replace = TRUE,
prob = date_prob))
rideTable <- 1:20000 %>%
map(function(x) {
spots <- sample(nrow(locs), 2, replace = FALSE)
data.frame(origin = spots[1],
destination = spots[2],
driver = sample(drivers$pid, 1),
rider = sample(allNames$passengers$pid, 1))
}) %>%
bind_rows() %>%
mutate(date = ride_date,
rideid = 1:20000)
sents <- sentimentr::combine_data("hotel_reviews") %>% select(text) %>% lapply(function(x)strsplit(x, ".")) %>% unlist()
sents <- sents[nchar(sents) > 10]
rateobj <- data.frame(rdid = c(1,2),
rated = c("Passenger", "Driver"))
ratings <- data.frame(rideid = rep(1:20000, 2),
rdid  = rep(1:2, each = 20000),
assigned = runif(40000, 0, 1),
rating = sample(5,40000, replace = TRUE, prob = ppois(1:5, 3)),
comments = NA)
ratings$comments[ratings$assigned > .9] <- sents[sample(1:length(sents),
sum(ratings$assigned > .9),
replace = TRUE)]
ratings <- ratings %>%
filter((rdid == 1 & assigned < .8) | (rdid == 2 & assigned < .6)) %>%
select(-assigned)
# Note: With all this repetition we should make a function.
if (!dbExistsTable(con, "drivers")) {
dbWriteTable(con, "drivers", drivers,
row.names = FALSE)
}
if (!dbExistsTable(con, "passengers")) {
dbWriteTable(con, "passengers",
allNames$passengers,
row.names = FALSE)
}
if (!dbExistsTable(con, "dispatchers")) {
dbWriteTable(con,
"dispatchers",
allNames$dispatchers,
row.names = FALSE)
}
if(!dbExistsTable(con, "places")) {
aa <- try(dbExecute(con, "CREATE EXTENSION postgis;"))
dbWriteTable(con,
"places",
locs,
row.names = FALSE)
}
if (!dbExistsTable(con, "rides")) {
dbWriteTable(con, "rides", rideTable,
row.names = FALSE)
}
if (!dbExistsTable(con, "model")) {
dbWriteTable(con, "model", car_make,
row.names = FALSE)
}
if (!dbExistsTable(con, "cars")) {
dbWriteTable(con, "cars", cars,
row.names = FALSE)
}
if (!dbExistsTable(con, "ratings")) {
dbWriteTable(con, "ratings", ratings,
row.names = FALSE)
}
if (!dbExistsTable(con, "rateobj")) {
dbWriteTable(con, "rateobj", rateobj,
row.names = FALSE)
}
dbDisconnect(con)
places
no_cars <- 2100
car_make <- data.frame(modelid = 1:4,
make = c("Ford", "Fiat",
"SAIC", "Tata"),
model = c("Fiesta", "500",
"Roewe", "Tigor"),
stringsAsFactors = FALSE)
lsa <- function(x) { sample(letters, x,
replace = TRUE) }
nsa <- function(x) { sample(0:9, x, replace = TRUE) }
cars <- data.frame(carid = 1:no_cars,
modelid = sample(car_make$modelid,
2100,
replace = TRUE),
license = paste0(lsa(2100),
nsa(2100),
lsa(2100),
nsa(2100),
lsa(2100),
nsa(2100)))
if (!dir.exists("data/vanhoods/")) {
if (!dir.exists("data")) {
dir.create("data") #create a folder in directory
}
dir.create("data/vanhoods")
}
if (!file.exists("data/vanhoods/")) {
download.file("ftp://webftp.vancouver.ca/OpenData/shape/local_area_boundary_shp.zip",
"data/vanhoods/local_area_boundary_shp.zip")
unzip("data/vanhoods/local_area_boundary_shp.zip",
exdir = "data/vanhoods")
}
if (!dir.exists("data/vanhoods/")) {
if (!dir.exists("data")) {
dir.create("data") #create a folder in directory
}
dir.create("data/vanhoods")
}
if (!file.exists("data/vanhoods/")) {
download.file("ftp://webftp.vancouver.ca/OpenData/shape/local_area_boundary_shp.zip",
"data/vanhoods/local_area_boundary_shp.zip")
unzip("data/vanhoods/local_area_boundary_shp.zip",
exdir = "data/vanhoods")
}
places <- sf::st_read("data/vanhoods/local_area_boundary.shp")
